This project has basic .net core C# examples

Terms - 

------------------------------------------------------------------------------------------------------

Boxing and Unboxing (Occurs at runtime) - 

Boxing - The process of Converting a Value Type (char, int etc.) to a Reference Type(object) is called Boxing.
Boxing is implicit conversion process in which object type (super type) is used.
The Value type is always stored in Stack. The Referenced Type is stored in Heap.
Example :
int num = 23; // 23 will assigned to num
Object Obj = num; // Boxing

Unboxing - The process of converting reference type into the value type is known as Unboxing.
It is explicit conversion process.
Example :
int num = 23;         // value type is int and assigned value 23
Object Obj = num;    // Boxing
int i = (int)Obj;    // Unboxing

------------------------------------------------------------------------------------------------------

Generics and Boxing/Unboxing

Boxing is the process of converting a value type to object/reference type (or as the name suggests wrapping it inside the object container).
Unboxing means converting the object to a value type. or unwrapping the type from the object container.

Boxing/Unboxing are costly operations, and it is always better to not rely on them heavily in your code.

Advantage of using Generics - 

	With Generics you avoid doing boxing/unboxing since you are dealing with the parameter type T,
	which is a natural parameter that the compiler will replace it with the concrete type at compilation time 
	without doing the boxing operation at runtime.


------------------------------------------------------------------------------------------------------

Extension Methods and its advantage

Extension methods are used to add new functionality to existing types without modifying the original types or creating 
a new derived type. 
That is adding functionality to the existing type without modifying or without extending.
In C#, an extension method is a static method of a static class, where the "this" keyword is used as the first parameter
of the method. This allows the method to be called as if it were an instance method on the type of the first parameter. 

Advantages:

1. The main advantage of the extension method is to add new methods in the existing class without using inheritance.
2. You can add new methods in the existing class without modifying the source code of the existing class.
3. It can also work with sealed class.

Properties:

1. An extension method must be defined in a top-level static class.
2. An extension method with the same name and signature as an instance method will not be called.
3. When an extension method is defined with the same name and the signature of the existing method, 
then the compiler will print the existing method, not the extension method. 
Or in other words, the extension method does not support method overriding.
4. Multiple binding parameters are not allowed means an extension method only 
contains a single binding parameter (1st param with "this" keyword) 
But you can define one or more normal parameter in the extension method.

Ex -

class Geek {
   
	  // Method 1
	  public void M1() 
	  {
		  Console.WriteLine("Method Name: M1");
	  }
   
	  // Method 2
	  public void M2()
	  {
		  Console.WriteLine("Method Name: M2");
	  }
   
	  // Method 3
	  public void M3()
	  {
		  Console.WriteLine("Method Name: M3");
	  }
    
 }

 static class NewMethodClass {
  
	  // Method 4
	  public static void M4(this Geek g)
	  {
	  	Console.WriteLine("Method Name: M4");
	  }
  	  
	  // Method 5
	  public static void M5(this Geek g, string str)
	  {
	  	Console.WriteLine(str);
	  }
}

public class GFG {
  
    // Main Method
    public static void Main(string[] args)
    {
        Geek g = new Geek();
        g.M1();
        g.M2();
        g.M3();
        g.M4();
        g.M5("Method Name: M5");
    }
}

------------------------------------------------------------------------------------------------------

Extension Methods vs Static Methods (Diff based upon usage both as used to create utility methods)

Extension methods are modified static methods.

We use extension methods when we want to add utility methods to existing types, especially if 
we don't have access to modify the original type's source code. They're particularly useful for 
enhancing readability and providing syntactic sugar.
Usage - Add utility methods to existing type for types which we dont want to modify or extend.

We use static methods when you want to provide utility functions that don't need any state or 
behavior from an instance. Static methods are also used for factory methods or other functionalities 
that don't involve instance-specific behavior.
Usage - Add utility methods when we dont need to maintain any state or instance behavior (object).
------------------------------------------------------------------------------------------------------


CLR and CTS - 

CLR - Common Language Runtime (CLR) - A runtime "environment" for Managed Code

.Net Framework provides "runtime environment" called Common Language Runtime (CLR). It provides an environment 
to run all the .Net Programs. The code which runs under the CLR is called as Managed Code. Programmers need
not to worry on managing the memory if the programs are running under the CLR as it provides memory management 
and thread management.

Programmatically, when our program needs memory, CLR allocates the memory for scope and de-allocates the memory 
if the scope is completed.

Language Compilers (e.g. C#, VB.Net, J#) will convert the Code/Program to Microsoft Intermediate Language (MSIL) 
inturn this will be converted to Native Code by CLR.

	Purpose :
	1. Provide common runtime environment.
	2. Memory management. (Automatic memory allocation/deallocation)
	3. Conversion of COMPILED CODE to NATIVE CODE. In C# compiler would convert language specific code to MSIL.
	Then this MSIL will be converted to Native code by using CLR (Which will internally use a JIT compiler).


Common Type System (CTS) - Deals with Datatypes to be used by managed code

Common Type System (CTS) describes the datatypes that can be used by managed code. CTS defines how these types are declared, 
used and managed in the runtime.
For Communicating between programs written in any .NET complaint language, the types have to be compatible on 
the basic level.

The common type system supports two general categories of types: 

	Value types:

	Value types directly contain their data, and instances of value types are either allocated on the "stack" or 
	allocated inline in a structure. Value types can be built-in (implemented by the runtime), user-defined,
	or enumerations.

	Reference types:

	Reference types store a reference to the value's memory address, and are allocated on the "heap" Reference types 
	can be self-describing types, pointer types, or interface types. The type of a reference type can be determined 
	from values of self-describing types. Self-describing types are further split into arrays and class types. 
	The class types are user-defined classes, boxed value types, and delegates. 



Common Language Specification (CLS) - (Deals with rules how datatypes should be written for managed code)

CLS stands for Common Language Specification and it is a subset of CTS. It defines a set of rules and restrictions 
that every language must follow which runs under the .NET framework. The languages which follow these set of rules 
are said to be CLS Compliant. In simple words, CLS enables cross-language integration or Interoperability.

For Example

If we talk about C# and VB.NET then, in C# every statement must have to end with a semicolon. it is also 
called a statement Terminator, but in VB.NET each statement should not end with a semicolon(;).


------------------------------------------------------------------------------------------------------

Reflection 

	Reflection in C# is a powerful feature that allows you to inspect and interact with the metadata of assemblies, types, and members at runtime.
	Reflection is commonly used for tasks like creating instances of types, invoking methods, accessing properties, and more, without knowing the 
	details at compile time.
	Here are some key aspects of reflection in C#:

		1. Reflection enables you to:
			a. Inspect Metadata: Examine the contents of an assembly, such as its types, methods, properties, and fields.
			b. Create Instances: Dynamically create instances of types.
			c. Invoke Methods: Call methods on objects dynamically.
			d. Access Fields and Properties: Get or set the values of fields and properties.

		2. Common Uses of Reflection
			a. Dynamic Type Discovery: Useful in scenarios where types are not known at compile time.
			b. Late Binding: Allows invoking methods on objects dynamically.
			c. Metadata Inspection: Tools like Visual Studio use reflection to provide IntelliSense.
			d. Custom Attributes: Retrieve custom attributes applied to types and members.

		3. Example: Here’s a simple example demonstrating how to use reflection to inspect a type and invoke a method:
			using System;
			using System.Reflection;

			public class Example
			{
				public void SayHello()
				{
					Console.WriteLine("Hello, world!");
				}
			}

			class Program
			{
				static void Main()
				{
					// Get the type of the Example class
					Type type = typeof(Example);

					// Create an instance of the Example class
					object instance = Activator.CreateInstance(type);

					// Get the MethodInfo object for the SayHello method
					MethodInfo method = type.GetMethod("SayHello");

					// Invoke the SayHello method on the instance
					method.Invoke(instance, null);
				}
			}

		4. Advanced Features
			Custom Attributes: Define and retrieve custom metadata.
			Assembly Loading: Load assemblies at runtime and inspect their contents.
			Dynamic Method Invocation: Call methods dynamically using MethodInfo.

		5. When to Use Reflection
			Dynamic Scenarios: When you need to work with types that are not known at compile time.
			Frameworks and Libraries: Useful in building frameworks that need to inspect and manipulate code.
	
		6. Performance Considerations
			Reflection can be slower than direct code invocation due to the overhead of inspecting metadata and invoking members dynamically. 
			Use it judiciously, especially in performance-critical applications.

	NOTE - Late binding is often implemented using reflection. When you use late binding, the runtime uses reflection to find and invoke the appropriate 
	methods or access properties on the object.

	While reflection is powerful, it comes with some trade-offs:

		1. Performance: Reflection can be slower compared to direct method calls or property access since it involves 
		runtime lookups and checks.
		2. Compile-Time Safety: Reflection bypasses many compile-time checks, so errors might only be discovered at runtime.
		3. Security: Reflection can potentially allow access to private members and methods that would be otherwise inaccessible.

------------------------------------------------------------------------------------------------------

Late Binding (Involves the involvement of reflection)

	Late binding in C# refers to the process of resolving and invoking methods or accessing properties of an object at runtime, 
	rather than at compile-time. This allows for more dynamic and flexible code, especially when the exact type of the object is not known
	until the program is running.

	Characteristics -
		a. Runtime Resolution: The type of the object and the methods or properties it contains are determined at runtime.
		b. Flexibility: Allows for more flexible code, as you can work with objects whose types are not known until runtime.
		c. Dynamic Objects: Often involves the use of the dynamic keyword or reflection to achieve late binding.

	NOTE - Typically late binding can be achieved using dynamic keyword or using reflection implementation directly.
	When you use late binding, the runtime uses reflection to:
		a. Inspect Metadata: Determine the types, methods, properties, and fields of an object.
		b. Invoke Methods: Dynamically call methods on objects.
		c. Access Members: Get or set the values of fields and properties.
	
	Performance Considerations -
		a. Slower Execution: Late binding can be slower than early binding because it involves runtime type checking and method resolution.
		b. Use Cases: Ideal for scenarios where flexibility is more important than performance, such as working with COM objects, dynamic 
		languages, or plugins.

------------------------------------------------------------------------------------------------------

Early Binding Vs Late Binding

	Early Binding -
		a. Compile-Time Resolution: The type of the object and the methods or properties it contains are determined at compile-time.
		b. Type Safety: The compiler checks for the existence of methods and properties, ensuring type safety and reducing runtime errors.
		c. Performance: Faster execution because method calls are resolved at compile-time.
		d. IntelliSense Support: Provides full IntelliSense support in IDEs like Visual Studio, showing available methods and properties.
		e. Usage: Commonly used in scenarios where the types are known at compile-time.

	Late Binding -
		a. Runtime Resolution: The type of the object and the methods or properties it contains are determined at runtime.
		b. Flexibility: Allows for more dynamic and flexible code, especially useful when working with types not known until runtime.
		c. Performance: Slower execution due to the overhead of resolving methods and properties at runtime.
		d. No Compile-Time Type Checking: The compiler does not check for the existence of methods and properties, which can lead to runtime 
		errors if they are not found.
		e. Usage: Often used in scenarios involving dynamic types, COM objects, or reflection.

------------------------------------------------------------------------------------------------------

Var vs Dynamic

	In C#, both var and dynamic (keywords) are used to declare variables without explicitly specifying their types, but they have distinct 
	differences in how they operate:

	1. Var - It is early binded. So when value is assigned compiler will be able to detect the metadata like what kind of value 
	it contains.
		a. Statically Typed: The type of the variable is determined at compile-time based on the assigned value.
		b. Type Safety: Once the type is inferred, it cannot be changed. The compiler enforces type checking.
		c. IntelliSense Support: Provides full IntelliSense support in Visual Studio, showing available methods and properties.
		d. Usage: Commonly used for local variables where the type is obvious from the right-hand side of the assignment.
		e. Code: 

			var number = 10; // Inferred as int
			var text = "Hello"; // Inferred as string

			// Compiler error if you try to assign a different type
			// number = "World"; // Error: Cannot implicitly convert type 'string' to 'int'

	2. Dynamic - It is late binded. It is binded during runtime. So what value has been assigned would not be evaluated by compiler.
		a. Dynamically Typed: The type of the variable is determined at runtime, allowing for more flexibility.
		b. No Compile-Time Type Checking: The compiler does not check the type, which can lead to runtime errors if the operations are invalid.
		c. No IntelliSense Support: Limited IntelliSense support, as the type is not known until runtime.
		d. Usage: Useful in scenarios where the type is not known until runtime, such as working with COM objects, dynamic languages, or reflection.
		e. Code: 
			
			dynamic number = 10; // Initially an int
			number = "Hello"; // Now a string

			// No compile-time error, but runtime error if invalid operation
			// number.NonExistentMethod(); // Runtime error: 'string' does not contain a definition for 'NonExistentMethod'

			----------------------------------------------------------

			//Even if some error will be assigned to it say 
			
			dynamic a = "ABC";
			int t = a.length //It must be a.Length (Caps L)
			//this would not be any error during compile time but during run-time there would be exceptions.
 
	Difference -
		a. Type Determination: var is determined at compile-time, while dynamic is determined at runtime.
		b. Type Safety: var ensures type safety at compile-time, whereas dynamic allows for more flexibility but at the cost of potential runtime errors12.
		c. IntelliSense: var provides full IntelliSense support, while dynamic does not.
		d. Method Parameters: Dynamic can be used as function parameters, var cant be used as function parameter

	More on dynamic usage -
		Yes, the dynamic keyword in C# internally uses reflection. Here’s a bit more detail:

		How dynamic Uses Reflection
		
		Runtime Type Resolution: When you use the dynamic keyword, the actual type of the variable is resolved at runtime. This involves 
		inspecting the metadata of the type, which is a core aspect of reflection.

		Method Invocation: When you call a method on a dynamic object, the runtime uses reflection to find and invoke the appropriate method.
		This allows for late binding, where the method to be called is determined at runtime rather than compile-time.

	Additional advantage of Dynamics -
		Simplicity: Using dynamic simplifies the code, making it more readable and maintainable compared to using reflection directly.
		Performance: While dynamic uses reflection, it also includes some optimizations like caching method calls to improve performance

------------------------------------------------------------------------------------------------------

Method Overriding - 

	NOTE - Reflection is not required for Method Overriding but it can be used. Method Overriding uses Vtable Lookup and does not use Late Binding. 

	Method overriding in C# does not inherently use reflection. Instead, it is a feature of object-oriented programming where a derived class provides a 
	specific implementation of a method that is already defined in its base class. This is done at compile-time and does not involve reflection.

	Method overriding in C# is indeed a form of dynamic polymorphism, but it does not involve late binding. Instead, it uses a mechanism 
	called virtual method dispatch or vtable lookup, which is resolved at runtime but is not the same as late binding.

	Dynamic Polymorphism and Method Overriding
		a. Dynamic Polymorphism: Allows a method to behave differently based on the object that invokes it. This is achieved through method overriding.
		b. Virtual Methods: The base class method must be marked with the virtual keyword, and the derived class method must use the override keyword.

	Runtime Resolution
		a. Virtual Method Table (vtable): When a method is overridden, the runtime uses a vtable to determine which method implementation to call.
		This lookup happens at runtime, allowing the correct method to be invoked based on the actual object type.

		b. Not Late Binding: Although the method resolution occurs at runtime, it is not considered late binding because the method signatures are known
		at compile-time, and the vtable mechanism is used for dispatch.

	Reflection and Method Overriding
		While method overriding itself does not use reflection, you can use reflection to inspect and invoke overridden methods at runtime. 
		Here’s how you can do it:

		Example Using Reflection to Invoke an Overridden Method:
			using System;
			using System.Reflection;

			public class BaseClass
			{
				public virtual void Display()
				{
					Console.WriteLine("BaseClass Display");
				}
			}

			public class DerivedClass : BaseClass
			{
				public override void Display()
				{
					Console.WriteLine("DerivedClass Display");
				}
			}

			class Program
			{
				static void Main()
				{
					BaseClass obj = new DerivedClass();
					MethodInfo method = obj.GetType().GetMethod("Display");
					method.Invoke(obj, null); // Output: DerivedClass Display
				}
			}

 ------------------------------------------------------------------------------------------------------

 Const vs Readonly

	Const - for unchangable value added at compile time.
	Readonly - for unchangable value added at run time.
 
 ------------------------------------------------------------------------------------------------------

 C# value type vs reference type

 Value type - A data type which holds a data value within its own memory space. That is they directly contains value. 
 So when used with functions whenever we pass the value in the parameter, the parameter will create its own memory space.
 Holds value in Stack.	
 Ex - All basic/primitive data types (except string) + Struct + enum. Default value is some specific value ex- for int its 0.

 Reference type - A reference type does not hold the value directly rather it will hold the value of the address 
 where its actually value is actually stored. 
 The default value of a reference type variable is "null" when they are not initialized. Null means not refering to any object.
 When used with function no new copy is created instead address is passed.
 Holds value in Heap.
 Ex - String, stringbuilder, array (even its elements are value type), class, delegate. Default value is null.


 ------------------------------------------------------------------------------------------------------
 
 Serialization:

	Serialization is the process of converting objects or data structures into a format that can be easily 
	stored or transmitted, usually as a stream of bytes/XML/JSON. 

 Deserialization:

	Deserialization is the process of reconstructing objects or data structures from their serialized form. 
	It takes the data stored in a format (such as binary, XML, or JSON) and creates instances of objects or 
	data structures from it.

 
 ---------------------------------------------------------------------------------------------------

 IS vs AS keywords

 IS keyword - Will be used to check. Ex - If(abc is string)
 AS keyword - Will be used to convert. Ex - string x = abc as string;


 ---------------------------------------------------------------------------------------------------

 Stacks and Heaps	

 1) Primitive data type will be stored in Stacks. Stack has faster access
 and Reference types like objects are stored in Heaps. Heap has slower access.

 2) Now for objects say 
 Object obj1 = new Object();
 obj1.Name = "ABC;
 That is obj1 is stored on heap (with memory reference) and its memory reference original value is stored in stack.
 
 In stack data has to be pushed/removed from top only 
 but in heap data can be pushed or removed in any order.

 In stack recursion calls fills it up quickly 
 for heap recursion calls fills it up slowly

 Stack - We get stackOverflow when memory is exhausted. By default primitive variables get wiped off once they loose scope.
 Heap - GC - It is a special thread created by .NET runtime to monitor allocations of heap space.
 It only collects heap memory since objects are only created in heap

------------------------------------------------------------------------------------------------------

 Garbage Collector
 
	Summary - GC cleans unreferenced memory of Managed Objects. If there is any unmanaged objects like files then we have to manually
	write code to clean it. Unmanaged objects are typically cleaned using destructors. 

	It is a background process which runs in the background and cleans unreferenced managed objects from memory.
	It will clean objects once objects are out of scope.

	Garbage collector does not work on premitive types as it does not work on Stack. (These primitive types will be automatically
	cleaned once they go out of scope).

	GC cleans when - Managed resources are those which are pure .net objects and these objects are controlled by .net CLR. They are cleaned by GC.
	GC does not clean when - Unmanaged resources are those which are not managed by .net CLR like Files,Conn objects (for DB) etc. They are not cleaned by GC.

	Note - Total Memory of .net application = Managed Memory + Unmanaged Memory + Stack memory

	GC generations - They are logical buckets and each bucket defines how old the objects are. They are GC0, GC1, and GC2
	So,
		GC0 - It contains short lived objects.
		GC1 - It contains intermediate lived objects.
		GC2 - It contains long lived objects.
		Purpose - Having generations have good performance effect. So objects in GC0 will be visited by GC more than the objects in GC2.

	Note - Managed code will be cleaned by GC. And for unmanaged code we need to explicitly clean them by using Destructors or related processes.
	
	"Destructor" -> ~Constructor() Name -
		Here the unmanaged code gets cleaned. The Destructor is called implicitly by the .NET Framework’s Garbage collector 
		and therefore programmer has no control as when to invoke the destructor. An instance variable or an object is eligible for 
		destruction when it is no longer reachable.

		1. When we have Destructor in our code the GC has to work more and will have to do more trips to clean.
		2. A Destructor has no return type and has exactly the same name as the class name (Including the same case).
		3. A Destructor does not accept any parameters and modifiers.
	
	Issues with destructors -
		When destructors are written in the code it cleans unmanaged objects. But when the destructors are supposed to be called its not controlled by 
		programmers rather it is invoked when the object is no more used.
		This invocation is done by a periodical check from GC. So GC has to peek and check whether destructors has to be invoked. So this delays GC own tasks.
		So if we have a destructor then GC will give priority to cleaning based upon the destructor first, then it will clean rest of the references to be cleaned by GC.
	
		So, having an empty destructor is bad as it may push unused references of GC0 to GC1 and so on.
	
	"Finalize" - It is same as destructor internally Destructor calls Finalize.
	
	Q. Explain Dispose pattern? - This fixes the issue of GC peeking multiple times to invoke destructor
	
		This will tell the flow not to prioritize call the destructor call (first) and the unreferenced managed code will be handled (as the normal flow). 
		With this message GC will claim the unreferenced managed objects as without waiting for the Destructor.
		 
		Here GC.SuppressFinalize is used, it is a method in C# that is used to prevent the garbage collector from calling the finalizer (destructor) of an object.
		This is particularly useful in the implementation of the Dispose pattern to optimize resource cleanup.
	
		public class SomeClass : IDisposable{
	
			~SomeClass(){
			}
	
			public void Dispose(){
				//Code to clean
				GC.SuppressFinalize(this);
			}
	
		}
	
		public class CallingClass{
	
			public void MyFunct1(){
				SomeClass obj = new SomeClass();
				//Some work
				obj.Dispose();	//Calling dispose of the class
			}
	
		}
	
		NOTE - 
			Why Use GC.SuppressFinalize?
			Performance Optimization: Calling GC.SuppressFinalize improves performance by preventing the garbage collector from adding the
			object to the finalization queue, which can be an expensive operation.
			
			Resource Management: Ensures that resources are released in a timely manner without waiting for the garbage collector to call the finalizer.

		Advantage -

		a. Deterministic Cleanup: Ensures resources are released as soon as they are no longer needed.
		b. Performance: Reduces the overhead associated with finalizers by allowing explicit resource cleanup.
		c. Reliability: Provides a structured approach to resource management, reducing the risk of resource leaks.
	
	******************************************
	Here we have an important Concept - Why do use "using" statement for using unmanaged code such as network connections?

	Because implementing "using()" will define a scope, once the flow goes outside this scope then objects will be disposed automatically. 

	So we modify the code above

		public void MyFunct1(){

			using(SomeClass obj = new SomeClass())
			{
				//obj.Dispose();	//Automatically calling dispose of the class
			}
		}


	******************************************

	Q. Can we force Garbage Collector to run?
		Yes by calling GC.Collect();

		Note - GC.Collect() can be placed anywhere in the code as required but it is a good practice if we have a Dispose() method 
		then call GC.Collect() after the Dispose();

		Also GC.Collect() - Simple call
		GC.Collect(0) - Call gen 0 
		GC.Collect(1) - Call gen 1
		GC.Collect(2) - Call gen 2

		Note - It is recommended not to explicitly call GC.Collect() if not needed. As it will be smartly called.

	Q. How can we detect a bad memory and its source of issue?

		Ans - We will use performance profiler.
		We will check how .net objects are allocated.
		We need to check which portion of the code has huge memory allocation and then class needs to be refactored.

	Q. What is memory leak?
		Its a situation where memory used by the application is not returned to the OS even when the application exits.

		Concept - Total Memory of .net application = Managed Code + Unmanaged Code + Stack mem
			We also have primitive variables but they will be released from Stack once they are out of scope

	Q. Can a .net application have memory leak as we already have a Garbage Collector?
		We can still have memory leaks for unmanaged codes as GC does not work explicitly on unmanaged code.

	Q. Explain Strong references vs Weak references?
		Concept - Object created -> Object Removed -> After some time GC runs. So there is some Delta before the GC actually collects.

		"Strong reference" - It is a normal object. i.e once its reference is not needed it will be claimed by GC. 
		Here even if there is some time (Delta) before the next GC run the object is not accessible during this delta.

		"Weak reference" - It is a object which permits the garbage collector to collect itself while still 
		allowing the application to access the object till the next GC run (during this delta). So here the object marks itself for 
		GC collect but will be available during the delta before the actual GC run.

		Ex - 

		public class MyClass{
	
			static WeakReference weak = new WeakReference(null);

			public void Func1()
			{
				var obj = new SomeClass();

				weak.Target = obj; 
				//weak.IsAlive	//If the obj is alive then we will access it.
			}
		}


		Ex - 

		class Program
		{
			static WeakReference weakRef = new WeakReference(null);

			static void Main(string[] args){

				Func1(); //SomeClass is called
	
				while(1==1){
					SomeClass gc = new SomeClass(); //SomeClass is called again - Provoking GC when the reference ends
					Console.WriteLine(weakRef.IsAlive);	//Checking if still this object is available
				}
			}

			static void Func1(){
				SomeClass t = new SomeClass();
				weakRef.Target = t;
			}


		}

	Q. When we will use weak reference?
	Ans - Caching, object pooling. Wherever object creation is resource intensive caching and pooling can improve performance.


------------------------------------------------------------------------------------------------------

Bin vs Obj folders

In C# compilation is a two step process - compiling and linking.

Compilation Process - In compiling every code file is segregated into individual compiled units. These compiled units are stored in Obj folder.
Linking Process - Then each of these compiled files would be linked to form DLL file, exe file etc. These linked units are stored in Bin folder. 

Note - When build is done only whatever file is updated would be updated in the folders.

------------------------------------------------------------------------------------------------------

Common Collections -

	IEnumerable vs IEnumerator vs IQueryable

	IEnumerable is used when we want to iterate amongst our collection classes using foreach loop. Ex foreach(var a in col)
	So whichever collection we have it is internally using IEnumerable interface.

	And IEnumerable internally uses IEnumerator to iterate.

	Formats -
	
	IEnumerable -
		IEnumerable<string> data1 = employees; // employees is List<string>
		foreach(var d1 in data1)
		{
			.....
		}

	IEnumerator -
		IEnumerator<string> data2 = employees.GetEnumerator();
		while(data2.MoveNext())
		{
			.....
		}

	List (using IList) is derived from IEnumerable. 

	IQueryable - It is derived from IEnumerable too. Its better for usage with SQL. 

	Use -
		IQueryable<string> data3 = (IQueryable<string>)employees;
		foreach(var d3 in data3)
		{
			.....
		}

	Where IEnumerable is preferred and where IQueryable is preferred?
	- IEnumerable is preferred with in-memory collection. As such if we use any lambda expression with filters 
	then whole dataset will be fetched and then filters will be applied. Used from System.Collections namespace.

		IEnumerable<Employee> data4 = dbContext.Employees.Where(p => p.Name.StartsWith("H"));

	- IQueryable is preferred to fetch data from DB. As such if we use any lambda expression with filters 
	then whole dataset will be filtered at DB level and then filtered data will be fetched. Used from System.Linq namespace.

		IQueryable<Employee> data4 = dbContext.Employees.Where(p => p.Name.StartsWith("H"));

	Inheritence -

	--------IEnumerable---------- 
	|							|
	ICollection				IQueryable
	|
	IList


	IEnumerable (System.Collections) - Read Forward Only / Supports DEFERRED EXECUTION
		-Data iterated forward only. 
		-Supports for linq/lambda expressions.
		-Internally calls IEnumerator, which provides it the capability to iterate over collection.

	ICollection (System.Collections) - Read Forward Only / Supports DEFERRED EXECUTION
		- Inherit property of IEnumerable + Add, Update, Delete the collection.
		- Can use Count() to get the count of the items.

	IList (System.Collections) - Read can be done by index / Supports DEFERRED EXECUTION
		- Inherit property of ICollection + Support Indexing. As it supports 
		indexing so add or remove from middle of list is possible.
		- Supports DEFERRED EXECUTION.

	IQueryable (System.Linq) - Read Forward Only / Supports LAZY LOADING
		- Supports Linq to SQL.
		- It creates a query using an Expression Tree.



	Deferred execution vs Lazy Loading

	Deferred Execution - (Defer the execution till it is actually needed) 
		a. Deferred execution refers to delaying the actual execution of a query or operation until the result is actually needed.
		b. When you retrieve an IEnumerable result from a query (e.g., using LINQ), the query execution is deferred. 
		c. The actual work (such as querying a database) doesn’t happen until you start iterating over the collection.
		It’s like getting a ticket to claim the result later. The work is deferred until you actually use it.

		// The query is not executed yet; it's deferred.
		var query = from item in items
            where item.Price > 100
            select item;
		
		foreach (var item in query)
		{
			// Now the query is executed for each item.
			Console.WriteLine(item.Name);
		}

	Lazy Loading - (Load on demand) 
		a. Lazy loading loads data only when it’s explicitly requested.
		b. In the context of images, lazy loading means loading images on demand (e.g., when they come into view).
		It reduces the initial page payload and overall load time by loading resources only when necessary.
		Example (for images):
		Images are loaded only when they are visible in the viewport, improving page performance.
		This is common in web development, especially for large image galleries or infinite-scrolling pages.
	
	In summary, deferred execution is about delaying computation until the caller uses the result, while lazy loading 
	focuses on loading resources (like images) only when needed. Both concepts optimize performance and resource usage.

	List - 
	Use of List is preferable if we want immediate execution and faster response. With list we have a definite implementation
	of the Interface IList hence all the methods have proper implementation.

	Fast Response - As for the interfaces most of the operations will have deferred execution as such they have to track 
	and operate on the final collection. Moreover as the collection is not final in the case of deferred execution so for
	each iteration they might have to allocate memory. Faster response holds good if we need to iterate through the List.
	
	Note - With IEnumerable the memory consumption is more and performance is slow. Memory consumption is more as 
	for each operation we need GetEnumerator() run. List is best as it is materialized.Both in terms of speed and memory.
	Best if data is in memory. So if we have data in memory and we need to iterate, the best approach is to	convert to list 
	and iterate.

------------------------------------------------------------------------------------------------------

App Domain

Asp.Net introduces the concept of an Application Domain which is shortly known as AppDomain. 
It can be considered as a Lightweight process which is both a container and boundary. The .NET runtime uses an AppDomain 
as a container for code and data, just like the operating system uses a process as a container for code and data. 
As the operating system uses a process to isolate misbehaving code, the .NET runtime uses an AppDomain to isolate code 
inside of a secure boundary.

The CLR can allow the multiple .Net applications to be run in a single AppDomain.

The CLR isolates each application domain from all other application domains and prevents the configuration, security, 
or stability of a running .NET applications from affecting other applications.An AppDomain can be destroyed without 
effecting the other Appdomains in the process.

Ref : https://www.youtube.com/watch?v=DUq84e3cZyo

------------------------------------------------------------------------------------------------------

Yield (Keyword) - https://www.youtube.com/watch?v=4fju3xcm21M&t=2s
Is used for stateful iteration.

So if we have 2 methods 

static method1()
{
	foreach(var i in ValFunc())
	{
		
	}	
}

static ValFunc(){
	int cnt = 0;
	foreach(var i in listVal) //listVal(1 to 10))
	{
		cnt += i;
		yield return (cnt);	//Here for yield the state will be maintained that is 
							//for each iteration listval position i will be remembered in mem
	}
}

------------------------------------------------------------------------------------------------------

String comparison
Best way = 

Val.Equals("SqlServer", StringComparison.OrdinalIgnoreCase);



Object comparison
val1 == val2 -> Checks if references are same
val1.Equals(val2) -> Checks if contents are same

Note - For string it will be content comparision for both == and Equals

------------------------------------------------------------------------------------------------------

Aggregation vs Composition vs Association

	Interitance - IS A (relation) parent - child relation
	Using - HAS A (relation)

	What are the different types of USING / HAS A relation?
	Ans - Aggregation, Composition, Association

	Concept - Part-Whole relation - Ex - Wheel is a part of the whole car.
	For Composition and Aggregation has Part-Whole relationship

	Ex - 

	class Patient
	{
		public List<Problem> problems {get; set;}
		public Doctor Doctor {get; set;}
		
		public Patient(){
			Checkbed checkbed = new Checkbed();
			int bedNo = checkbed.Getbedno();

			Doctor doc = new Doctor();
			problems = new List<Problem>();
		}
	}

	Class Doctor{
		public Doctor(){
		
		}
	}

	Class Checkbed{
		public Checkbed(){
		
		}
	
		Getbedno(){
		
		}
	}


	Here class Patient is whole 
	and problems is a part of it.

	Please note on the vocabularies

	1. Composition Relation -

	That is the internal members of the class must have the same lifetime as of the class.

	In the above code Patient and Problems have similar lifetime. That is till the person is patient it is due to the problems.
	So Patient-person HAS A composition (1:1 relation). They are tightly coupled as the members are of the same class.

	2. Aggregation Relation - Aggregation is a part-whole relationship where both part and whole object 
	have different life time. They can have different life time.

	In the above code Patient and Doctors can have different lifetime. That is multiple doctors can have multiple patients.
	So Patient-doctor HAS A aggregation (M:N relation). There is no exclusive ownership. 
	Here no tightly coupled as Members are of different class.

	3. Association - It is a superset of composition and aggregation. It defines how two objects are dependent on each other.

	In the UML we can use 
	Composition -> Filled diamond
	Aggregation -> Empty diamond
	Association -> Arrow

------------------------------------------------------------------------------------------------------

IEnumerable vs IQueryable

Typically used for data fetching. If we have data fetched with filters then IEnumerable will simply fetch all the data and apply filter
from application. And IQueryable will first apply filter on the data at DB then pull the data to application.

IEnumerable 
1. It exists in System.Collections Namespace.
2. IEnumerable is best for querying data from in-memory collections like List, Array, etc.
3. IEnumerable is suitable for LINQ to Object and LINQ to XML queries.
4. IEnumerable doesn't support lazy loading. Hence not suitable for paging like scenarios.

IQueryable 
1. It exists in System.Linq Namespace.
2. IQueryable is best for querying data from out-memory (like remote Database, service) collections.
3. IQueryable is suitable for LINQ to SQL queries.
4. IQueryable support lazy loading. Hence it is suitable for paging like scenarios.

------------------------------------------------------------------------------------------------------

C# Copying objects -

Shallow Copy (Reference Copy) - Both original and copied object refer to same memory location.

	A Shallow Copy is about copying an object's value type fields into the target object and the object's reference types 
	are copied as references into the target object but not the referenced object itself. 
	It copies the types bit by bit. The result is that both instances are cloned and the original will refer to the same object.

	Class1 obj1 = new Class1();
	Class1 obj2 = obj1;

Deep Copy (New Pure Copy with new references) - Both original and copied object refer to different memory location.

	Deep Copy is used to make a complete deep copy of the internal reference types, for this we need to configure the object 
	returned by MemberwiseClone().

	Class1 : IClonable
	{
		public object Clone(){
			//Class1 obj = (Class1)this.MemberwiseClone();
			//return obj;

			return (Class1)this.MemberwiseClone();
		}
	}

	Class1 obj1 = new Class1();
	Class1 obj2 = (Class1)obj1.Clone();

------------------------------------------------------------------------------------------------------

Sealed classes are used to restrict the users from inheriting the class. 
A class can be sealed by using the sealed keyword. The keyword tells the compiler that the class is sealed, 
and therefore, cannot be extended. No class can be derived from a sealed class.

A method can also be sealed, and in that case, the method cannot be overridden. 
However, a method can be sealed in the classes in which they have been inherited. If you want to declare a method as sealed, 
then it has to be declared as virtual in its base class.


------------------------------------------------------------------------------------------------------

Serialize - Object to JSON/XML or Stream/string
Deserialize - JSON/XML/Stream to object

------------------------------------------------------------------------------------------------------

Struct vs Class vs Record

Classes - are reference types that store data on the heap. They are well-suited for creating complex objects that may 
require features like inheritance, polymorphism, and encapsulation. They can have private/public methods

Structs - are value types that store data directly on the stack. They are suitable for efficiently storing small and 
simple data types, making them a good choice when performance is a priority. They only have public methods.
They do not have default constructor. But can have parameterised constructor. Also no inheritance.

Records - like classes, are reference types that store data on the heap. However, records are specifically designed to 
represent immutable data structures. Immutable means that it cannot be changed once the data is set. Records provide 
built-in functionality for comparing and hashing objects, making them useful for scenarios where data integrity is important.
They can have constructor.

When should I use a class, a struct, or a record?
The best way to choose between a class, a struct, or a record is to consider the specific needs of your application. 

	If you need a data structure that is immutable and efficient, then a record is a good choice. 
	If you need a data structure that can be inherited from or that contains methods, then a class is a good choice.
	If you need a data structure that is lightweight and fast, then a struct is a good choice.


C# Class
A class is a fundamental concept in object-oriented programming. It is a user-defined data type that serves as a blueprint 
for creating objects and defining their properties (attributes) and behaviors (methods).
In C#, classes are reference types, which means they store data on the heap. They are great for creating complex objects that 
can inherit properties and behaviors from other classes, and they also support features like polymorphism and encapsulation.

As Classes are reference type, Its means that if you change the value of a field in one instance of a class, the value of 
that field will also change in any other instances of the class that refer to the same object.

We use classes to encapsulate related data and functionality, which makes it easier to reuse and maintain code.

Let’s consider an example:

using System;

public class Person
{
    public string Name { get; set; }
    public int Age { get; set; }

    public void SayHello()
    {
        Console.WriteLine("Hello, I am " + Name);
    }
}

In the above code snippet, we define a class called Person with two properties: Name and Age. We also have a method called “SayHello()” 
to greet the person. We can create objects of this class by using the “new” keyword, which allows us to access the properties and invoke methods.

class Program
{
    static void Main(string[] args)
    {
        Person person = new Person();
        person.Name = "Shekh Ali";
        person.Age = 29;

        person.SayHello();
        Console.ReadLine();
    }
}


C# Struct
A struct, or structure, is a value type in C#. Unlike classes, structs are lightweight and store data directly on the stack. They are primarily used
for storing small amounts of data, making them a good choice when performance is a priority.

As struct is a value type, meaning that when you create an instance of a struct, you are creating a copy of the struct’s data. It means that if you 
change the value of a field in one instance of a struct, the value of that field will not change in any other instances of the struct.

Let’s consider an example of struct in C#:

using System;

public struct Point
{				
    public int X { get; set; }
    public int Y { get; set; }

    public void Display()
    {
        Console.WriteLine("X: " + X + ", Y: " + Y);
    }
}

public class Program
{
    public static void Main()
    {
        Point point = new Point();
        point.X = 10;
        point.Y = 5;

        point.Display();
    }
}

Output : X: 10, Y: 5


C# Record
A record is a reference type that is immutable by default. It means that once you create an instance of a record, you cannot change the value of 
any of its fields. Records are a good choice for data structures that need to be consistent and reliable.

Record was introduced in C# 9.0. They are special objects that bring together the characteristics of structs and classes. Like classes, records 
are reference types and store data on the heap.

One of the benefits of records is that they provide built-in features for comparing and hashing objects, which helps to maintain data integrity. 
Records are particularly useful in situations where you need to ensure that your data remains consistent and unaltered.

Here are two examples to demonstrate the usage of “record” in C#. In one example, we will use it like a struct and the other like a class:

Example 1: Using “record” like a struct

public record Point(int X, int Y);

// Usage
Point point1 = new Point(5, 10);
Point point2 = point1 with { X = 8 };
Console.WriteLine($"Point 1: X={point1.X}, Y={point1.Y}");
Console.WriteLine($"Point 2: X={point2.X}, Y={point2.Y}");
Output:

Point 1: X=5, Y=10
Point 2: X=8, Y=10

In this example, the record keyword is used to defines a data structure called “Point,” which acts similarly to a struct. It has two properties, 
X and Y, representing coordinates.

When we want to make changes to a property, we use the "with" keyword to create a new instance of the record with the updated value. 
It shows that the record is immutable, meaning it cannot be changed directly; instead, a new instance is created with the modified property.

Example 2: Using “record” like a class

public record Person
{
    public string FirstName { get; init; }
    public string LastName { get; init; }
}

// Usage
Person person1 = new Person { FirstName = "Shekh", LastName = "Ali" };
Person person2 = new Person { FirstName = "Roman", LastName = "Chug" };
Console.WriteLine($"Person 1: {person1.FirstName} {person1.LastName}");
Console.WriteLine($"Person 2: {person2.FirstName} {person2.LastName}");
Output:

Person 1: Shekh Ali
Person 2: Roman Chug

In the above code example, we use the “record” keyword to create a structure similar to a class called “Person.” It has properties for the 
person’s first name and last name. It is important to mention that we use the init keyword for these properties, which means they can only 
be set when the object is first created.

This highlights the fact that records are immutable, meaning their values cannot be changed once they are set. We can create objects 
of this record type and access their properties in the same way we do with classes.



------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------


------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------


Can we call static from non static methods? Yes we can

Object copy

array clean
- Array.Clear(myArray, 0, myArray.Length); //For reference type

array to list

---------------------------------------------------------------------------------------------------------

Task.Delay() and Thread.Sleep() 

- Task is a wrapper over thread.

Both are used to introduce a delay or pause in the execution of code, but they have different use cases and behaviors, 
especially in asynchronous programming scenarios.

Task.Delay():

	Asynchronous: Task.Delay() is an asynchronous operation that is commonly used in asynchronous programming. 
	It returns a Task that represents a delay.
	
	Non-Blocking: When you use Task.Delay() in an asynchronous method, it allows the calling thread to continue executing other 
	tasks while waiting for the delay to complete. This is especially useful in scenarios where you want to avoid 
	blocking the main (UI) thread or consuming server resources unnecessarily.

	Cancellation Support: Task.Delay() supports cancellation through a CancellationToken. You can cancel the delay if needed.
	Recommended for Asynchronous Code: It's generally recommended for asynchronous code, such as in async/await patterns.

	Example in C#:

		async Task MyAsyncMethod()
		{
			// Do something before the delay
			await Task.Delay(1000); // Delay for 1 second (non-blocking)
			// Do something after the delay
		}
------------------------

Thread.Sleep():

	Synchronous: Thread.Sleep() is a synchronous method that causes the current thread to pause for a specified amount of time.
	It blocks the execution of the current thread.
	
	Blocking: While Thread.Sleep() is useful for introducing delays, it's important to note that it blocks the thread 
	on which it is called. This can lead to unresponsiveness in GUI applications and inefficient resource utilization 
	in server applications.
	
	No Cancellation: Thread.Sleep() does not support cancellation. Once it starts sleeping, it will continue for the specified duration.
	Historically Used: Thread.Sleep() has been used in traditional multi-threaded applications but is less suitable for modern 
	asynchronous and non-blocking programming.

	Example in C#:

	void MyMethod()
	{
		// Do something before the sleep
		Thread.Sleep(1000); // Sleep for 1 second (blocking)
		// Do something after the sleep
	}

	In summary, the choice between Task.Delay() and Thread.Sleep() depends on your specific use case:

	Use Task.Delay() in asynchronous code when you want to introduce a non-blocking delay, especially in async/await scenarios.
	
	Use Thread.Sleep() when you need a synchronous delay, but be cautious about using it in situations where blocking the current 
	thread may have negative impacts on responsiveness or resource utilization.

---------------------------------------------------------------------------------

Task.WaitAll() vs Task.WhenAll() [Ref : https://www.c-sharpcorner.com/article/understanding-task-waitall-and-task-whenall-in-c-sharp/]

Tasks in C# represent asynchronous operations. They provide a way to perform work on a separate thread and then continue 
the execution once the task is completed. Tasks can be parallelized, making them ideal for scenarios where multiple
operations can occur simultaneously, enhancing the overall performance of the application.

	*Task.WaitAll: Waiting for All Tasks to Complete (i.e waiting for group of tasks as a group response)
	(Thread stops till all the tasks gets completed and task reference is returned)
	
	Task.WaitAll is a synchronous method that blocks the current thread until all the provided tasks have completed execution.
	It's useful when you have multiple tasks that need to finish before proceeding further in your code. The method takes an 
	array of tasks as a parameter and waits for all of them to finish before allowing the program to continue.

	*Task.WhenAll: Awaiting All Tasks Concurrently (i.e waiting for individual tasks concurrently)
	(Thread continues to work, once all the tasks (working in background) get completed the task reference is returned)

	Task.WhenAll is an asynchronous method that returns a task that completes when all the provided tasks have completed execution.
	Unlike Task.WaitAll, it doesn't block the calling thread, allowing for a non-blocking and more responsive application.
	It's especially useful in asynchronous environments such as UI applications.


---------------------------------------------------------------------------------

Brief of .net background process

	Background task are those which run in the background without interfaring the primary process. They run as hosted service

	Hosted Service - In .NET Core (and later, .NET 5 and .NET 6), a Hosted Service is a long-running background service that 
	can be hosted within your application. Hosted Services are typically used for running tasks that need to run independently
	of HTTP requests, such as background processing, periodic tasks, or services that need to run continuously. 

	Status Code-
	 102 - Processing (for long running process)
	 
	 200 - OK
	 201 - Created 
	 202 - Accepted

	 400 - Bad Request (Expression not matching)
	 401 - Unauthorized
	 403 - Forbidden
	 404 - Not found
	 429 - Too many requests (for rate limiting)

	 500 - Intenal Server Error
	 501 - Not Implemented
	 502 - Bad Gateway
	 503 - Sevice Unavailable
	 504 - Gateway Timeout

--------------------------------------------------------------------------------

VERACODE (Security Vulnarability Testing)
	Veracode is a widely used application security testing (AST) tool that provides various scanning and analysis capabilities to 
	identify and mitigate security vulnerabilities in software applications. Veracode performs static analysis, dynamic analysis, 
	and software composition analysis to assess the security of applications, including web applications, mobile apps, 
	and desktop applications. 

	- Static Analysis (SAST):
		- Static analysis is also known as Static Application Security Testing (SAST).
		- Veracode scans the source code or binary code of an application without executing it.

	- Dynamic Analysis (DAST):
		- Dynamic analysis is also known as Dynamic Application Security Testing (DAST).
		- Veracode simulates real-world attacks by interacting with the running application.
	
	- Software Composition Analysis (SCA):
		- Software Composition Analysis focuses on identifying security vulnerabilities and outdated dependencies in third-party
		libraries and components.
		- Veracode scans the application's dependencies to check for known vulnerabilities or license compliance issues.

	Process we build the code and publish and then take the artifact and push it to Veracode Portal and scan. We get the scan report
	and do the fix.

---------------------------------------------------------------------------------

SONARCUBE (Code Quality Review)
	SonarQube, often referred to as SonarCube (although the correct name is SonarQube), is an open-source platform for continuous code
	quality and static code analysis. It is widely used by software development teams to analyze and improve the quality of their codebase.
	SonarQube provides a range of tools and features for code quality assessment, code review, and reporting.

---------------------------------------------------------------------------------

SCRUM CEREMONIES

	1. Backlog refinement meeting - The product owner, scrum master and the development team work together to discuss and prioritize backlog items.
	
	2. Sprint planning meeting - The team determines how much work they can take on from the prioritized backlog for the next sprint.
	This is based on the estimates of the item, and velocity of the team. The selected items from the product backlog become the sprint backlog 
	and goal of the sprint.
	
	3. The Daily Scrum - This is 15-min daily meeting sometimes called the "stand-up" meeting. The team has 3 question to discuss.
		- What has been accomplished since last daily scrum?
		- What will I accomplish before next daily scrum?
		- Is there anything blocking my work?
	
	4. Scrum of Scrums - For larger projects leads from each scrum meet and discuss about goals achievement.
	
	5. Sprint Review - At the end of each sprint, the development team demonstrate the work they have accomplished for the product owner, the scrum
	master and other key stakeholders. This is the opportunity to see, feel and touch the necessary features and get any feedback necessary before 
	signing off.
	
	6. Sprint Retro-spective - After the sprint ends and before the next sprint the development team meets and discuss and answer:
		- What worked well
		- What needs improvement
		- What did we learn
		- What still puzzles us
	This will be used for future planning

------------------------------------------------------------------------------

MOQ Testing

MS Test Case-

Create a project and create the MsTestCase project

	//Use of package
	using Microsoft.VisualStudio.TestTools.UnitTesting; 

	[TestClass]
	public class MyTestClass
	{
		[TestMethod]
		public void TestGetSum()
		{
			int a=9, b=7;
			var result = GetSum(a,b);

			//Positive scenario
			Assert.AreEqual(a+b, result);
			
			//Negetive Scenario
			Assert.AreNotEqual(a-b, result);
		}
	
		[TestMethod]
		public void TestGetFullName()
		{
			string firstName = "Raja";
			string lastName = "Ghosh";
			var result = GetFullNname(firstName, lastName);

			Assert.AreEqual(string.Concat(firstName, '', lastName), result);
			Assert.IsNotNull(result);		
		}
	
	}

	---------------------------------------------------------------------------------------

	Open test explorer to test
	We will get our TestClass coded above. Here we can either Run or Debug. 
	
	Once started we have the exclaimation sign in the test explorer infront of the test case.
	Once test is passed we have a check sign in front of the test case. 

	Inside each test method, you have three sections: Arrange, Act, and Assert.
		- Arrange: In this section, you set up the test environment, including preparing the test data and objects.
		- Act: This is where you execute the code you want to test.
		- Assert: Here, you verify that the actual result matches the expected result using assertion methods like Assert.AreEqual.


	using Microsoft.VisualStudio.TestTools.UnitTesting;

	[TestClass]
	public class MyTestClass
	{
		[TestMethod]
		public void TestAddition()
		{
			// Arrange

			// Prepare the test data and objects
			int a = 5;
			int b = 3;

			// Expected result
			int expectedSum = 8;

			// You can also set up any necessary context or objects here, e.g., initializing a database connection or creating objects to test

			// Act

			// Perform the actual operation to be tested
			int actualSum = MyMath.Add(a, b);

			// Assert

			// Verify that the operation produced the expected result
			Assert.AreEqual(expectedSum, actualSum, "Sum operation is incorrect.");
		}
	}

	------------------------------------------------------------------------------------------

	Mocking -
		Mocking in software development refers to the concept of simulating the behavior or returned objects of classes, 
		methods, or services that another part of the system under test depends on. Let’s break it down:

	Purpose of Mocking:
		When testing a specific component or unit of code, it’s essential to isolate it from its dependencies 
		(e.g., databases, web services, other classes).
		The goal is to ensure that the test focuses solely on the functionality of the unit being tested, 
		without being affected by external aspects of the code.
	
	What Are Mock Objects?:
		Mock objects allow you to mimic the behavior of real classes and interfaces.
		They act as stand-ins for actual dependencies, letting your test code interact with them as if they were real.
		By using mock objects, you can control the input and output of these dependencies during testing.
	
	MOQ Framework:
		MOQ is a popular mocking framework for .NET.
		It simplifies the creation of mock objects for unit testing.
		With MOQ, you can create test doubles (mocks) that simulate the behavior of real objects, allowing you to set specific 
		outcomes for method calls.

	Benefits of Mocking with MOQ:
		Control: You can specify how mock methods behave, what they return, and how they handle input parameters.
		Isolation: Mocking isolates the code you’re testing, ensuring it works independently without interference from other code.
		Verification: MOQ allows you to verify whether expected calls are made during testing
	
	
	
	
	Advantages of the MOQ framework over MSTest:

	Isolation and Mocking: (Important)
		- MOQ helps isolate code for unit testing by creating mock objects (fakes) dynamically.
		- With MOQ, you can mock dependencies (e.g., database calls, external services) without needing actual implementations.
		- MSTest also supports mocking, but MOQ’s dynamic generation of mock types simplifies the process.
	
	Strongly Typed and Readable:
		-MOQ’s API is built around lambda constructs, ensuring tests are strongly typed and easy to read.
		-You define expectations and behaviors using lambda expressions, making test setup concise and clear.
		-MSTest also provides mocking capabilities, but MOQ’s syntax is often more intuitive.
	
	Quick to Write:
		-MOQ reduces boilerplate code needed for creating test doubles.
		-Its concise syntax allows you to set up mocks quickly.
		-MSTest can be verbose in comparison, especially when dealing with complex scenarios.
	
	String-Based API for Protected Methods:
		-MOQ provides a string-based API to mock protected methods.
		-This feature allows you to mock non-public members easily.
		-MSTest lacks a built-in mechanism for directly mocking protected methods.
	
	In summary, MOQ simplifies mocking, offers a readable syntax, and speeds up test setup. While MSTest also supports mocking, 
	MOQ’s features make it a popular choice for .NET developers.
	

	------------------------------------------------------------------------------------------
	To test any service we will be using the Moq package

	Let us test a service class

	public interface IEmployee
	{
		Employee GetEmployeeById(int id);
	}

	The method is implemented in Employee Service + Controller Calls this service

	----------------------------------------------------------

	//New package added 
	using Moq; 

	[TestClass]
	public class MyTestClass
	{
		[TestMethod]
		public void TestGetEmployeeById()
		{
			var employee = new EmployeeModel()
			{
				Id = 1,
				Name = "ABC"
			};

			//Here we have IEmployee interface for the service
			//Using Mock we will create employee repo instance to be 
			//passed to the controller which we want to test.
			//Step 1 : Use new Mock<ServiceClassInterface> - To Activate
			//Step 2 : Use Setup() - To setup the method
			//Step 3 : Assert - Use asset to verify
		
			var employeeRepo = new Mock<IEmployee>();
			employeeRepo.Setup(p => p.GetEmployeeById(It.IsAny<int>())).Returns(employee);

			//The controller takes the injection of IEmployee
			var controller = new EmployeeController(employeeRepo.Object);

			var getEmployeeById = controller.GetEmployeeById(1);
			Assert.IsNotNull(getEmployeeById);

		}



		[TestMethod]
		public void TestGetSum()
		{
			int a=9, b=7;
			var result = GetSum(a,b);

			//Positive scenario
			Assert.AreEqual(a+b, result);
			
			//Negetive Scenario
			Assert.AreNotEqual(a-b, result);
		}
	
		[TestMethod]
		public void TestGetFullName()
		{
			string firstName = "Raja";
			string lastName = "Ghosh";
			var result = GetFullNname(firstName, lastName);

			Assert.AreEqual(string.Concat(firstName, '', lastName), result);
			Assert.IsNotNull(result);		
		}
	
	}

------------------------------------------------------------------------------------------------------------------------------


IAM stands for "Identity and Access Management." It is a framework of policies and technologies that organizations use to ensure that
the right individuals or systems have the appropriate level of access to resources and data within their computing environment. IAM is
crucial for maintaining security, compliance, and efficient operations in modern IT infrastructures.

Key components and concepts of IAM typically include:

	1. Identity Management: This involves creating and managing user identities, which can be individuals, devices, or applications. 
	Each identity is associated with specific attributes and permissions.

	2. Authentication: IAM systems use authentication methods to verify the identity of users or systems trying to access resources. 
	This can include passwords, multi-factor authentication (MFA), biometrics, and more.

	3. Authorization: After authentication, IAM systems determine what actions and resources an authenticated identity is allowed to access. 
	This is often done through role-based access control (RBAC) or permissions based on policies.

	4. Access Control: IAM systems enforce access control policies, ensuring that only authorized identities can access specific resources. 
	Access can be granted or denied based on predefined rules and conditions.

	5. Audit and Logging: IAM systems often include auditing and logging capabilities to track and record access attempts and actions 
	taken by users and systems. This helps with security monitoring and compliance reporting.

	6. Single Sign-On (SSO): SSO is a feature of IAM that allows users to log in once and access multiple systems or applications 
	without needing to re-enter their credentials each time. It enhances user convenience and security.

	7. Provisioning and De-provisioning: IAM systems facilitate the automated creation, modification, and removal of user accounts and
	permissions. This helps streamline administrative tasks and ensure that access is granted and revoked appropriately.

	8. Identity Federation: Identity federation allows organizations to extend authentication and authorization across different systems 
	or domains. It enables seamless access for users across multiple organizations or applications.

	9. Password Management: IAM systems often include password policies and self-service password reset capabilities to enhance security 
	and user convenience.

	10. Compliance and Governance: IAM plays a critical role in helping organizations meet regulatory compliance requirements by ensuring
	that access controls and audit trails are in place.

	IAM solutions are widely used in various industries and are especially important in cloud computing environments, where managing access 
	to cloud resources and services is essential. Popular IAM providers include AWS Identity and Access Management (IAM),
	Azure Active Directory, and Google Cloud Identity and Access Management, among others.

	It primarily deals with Authorization, Authentication, User management & Credential Management

----------------------------------------------------------------------------------------------------

Throw Vs Throw ex Vs Throw New 

throw : If we use "throw" statement, it preserve original error stack information. 
In exception handling "throw" with empty parameter is also called re-throwing the last exception.

throw ex : If we use "throw ex" statement, stack trace of exception will be replaced with a stack 
trace starting at the re-throw point. It is used to intentionally hide stack trace information.

throw new Exception(ex.Message); is even worse. It creates a brand new Exception instance, 
losing the original stack trace of the exception.

-------------------------------------------------------------------------------------------------

STATIC CONSTRUCTOR

	C# supports two types of constructors, a class constructor (static constructor) and an instance constructor (non-static constructor).

	Static constructor is used to initialize static data members as soon as the class is referenced the first time, whereas an instance
	constructor is used to create an instance of that class with the <new> keyword. 

	A static constructor does not take access modifiers or have parameters and can't access any non-static data member of a class.

	Since static constructor is a class constructor, it is guaranteed to be called as soon as we refer to that class or by creating 
	an instance of that class.

	Use case of Static Constructor -

	You may say, why not initialize static data members where we declare them in the code? Like this,

		private static int id = 10;
		private static string name = "jack";

	Static data members can certainly be initialized at the time of their declaration but there are times when value of one static member 
	may depend upon the value of another static member. In such cases we definitely need some mechanism to handle conditional initialization 
	of static members. To handle such a situation, C# provides static constructor.

		using System;
		namespace Constructor {

			class Test {
				//Declaration and initialization of static data member
				private static int id = 5;
				public static int Id {
					get {
						return id;
					}
				}
				public static void print() {
					Console.WriteLine("Test.id = " + id);
				}
				static void Main(string[] args) {
					//Print the value of id
					Test.print();
				}
			}
		}

------------------------------------------------------------------




